{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb4882-6e31-479d-993f-b635b85aa776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277749c7-6e0c-45d9-b7fc-32d545bfa103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b221c02-45e7-4ba5-a757-03c616f4c1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55aee8-f3c6-4717-bd5f-58af211ed496",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create an empty list to store filenames\n",
    "filenames = []\n",
    "\n",
    "# Traverse the directory and collect filenames\n",
    "for dirname, _, files in os.walk('16000_pcm_speeches'):\n",
    "    for filename in files:\n",
    "        # Append the filename to the list\n",
    "        filenames.append(filename)\n",
    "\n",
    "# Sort the list of filenames\n",
    "filenames.sort()\n",
    "\n",
    "# Create full file paths by joining the sorted filenames with the directory path\n",
    "directory_path = '16000_pcm_speeches'\n",
    "file_paths = [os.path.join(directory_path, filename) for filename in filenames]\n",
    "\n",
    "# Print the sorted file paths\n",
    "for file_path in file_paths:\n",
    "    print(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9b3a8-8be9-4925-a31b-31887927908f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import librosa\n",
    "\n",
    "# Replace 'your_audio_file.wav' with the path to your audio file\n",
    "audio_file = '16000_pcm_speeches/Benjamin_Netanyau/2.wav'\n",
    "\n",
    "# Load the audio file with librosa to get the data and sample rate\n",
    "audio_data, sample_rate = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Play the audio file\n",
    "Audio(data=audio_data, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66272244-88a0-4e8f-838f-bed5de31efce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "# Loads mp3 file with a specific sampling rate, here 16kHz\n",
    "y, sr = librosa.load(\"16000_pcm_speeches/Benjamin_Netanyau/1.wav\", sr=16_000)\n",
    "\n",
    "\n",
    "# Plot the signal stored in 'y'\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.title(\"Audio signal as waveform\")\n",
    "librosa.display.waveshow(y, sr=sr);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e86802-01d4-4919-ba53-c5addf6b2113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "# Applies fast fourier transformation to the signal and takes absolute values\n",
    "y_freq = np.abs(scipy.fftpack.fft(y))\n",
    "\n",
    "# Establishes all possible frequency\n",
    "# (dependent on the sampling rate and the length of the signal)\n",
    "f = np.linspace(0, sr, len(y_freq))\n",
    "\n",
    "# Plot audio signal as frequency information.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.semilogx(f[: len(f) // 2], y_freq[: len(f) // 2])\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38936ec1-8432-4360-acdd-89813464d17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "# Compute short-time Fourier Transform\n",
    "x_stft = np.abs(librosa.stft(y))\n",
    "\n",
    "# Apply logarithmic dB-scale to spectrogram and set maximum to 0 dB\n",
    "x_stft = librosa.amplitude_to_db(x_stft, ref=np.max)\n",
    "\n",
    "# Plot STFT spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(x_stft, sr=sr, x_axis=\"time\", y_axis=\"log\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4b9c2-d770-4efd-96f7-7fb9a5320ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32b909-ae3a-4d16-bc5a-e0f58796769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_dir = \"Speaker-Identification\"\n",
    "data_dir = os.path.join(\"16000_pcm_speeches\")\n",
    "background_noise_dir = \"16000_pcm_speeches//_background_noise_\"\n",
    "speaker_folders = [\"Benjamin_Netanyau\", \"Jens_Stoltenberg\", \"Julia_Gillard\", \"Margaret_Tarcher\", \"Nelson_Mandela\"]\n",
    "speaker_paths = [\"16000_pcm_speeches//Benjamin_Netanyau\", \"16000_pcm_speeches//Jens_Stoltenberg\", \"16000_pcm_speeches//Julia_Gillard\", \"16000_pcm_speeches//Magaret_Tarcher\", \"16000_pcm_speeches//Nelson_Mandela\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d91b2-c708-412b-b143-3421cf3db549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "    # Display the MFCCs\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time', sr=sample_rate)\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.show()\n",
    "\n",
    "    return np.mean(mfccs.T, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78775bbf-dc4d-416e-a85c-d7cc01391227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d2f3b-f409-4ed1-8e4f-801983e9c848",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(speaker_paths)):\n",
    "    for file in os.listdir(speaker_paths[i]):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_name = os.path.join(speaker_paths[i], file)\n",
    "            class_label = speaker_folders[i]\n",
    "            print(file_name)\n",
    "            data = extract_features(file_name)\n",
    "            features.append(data)\n",
    "            labels.append(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171f369-df9e-41b4-92b6-d55dbb0e1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not features:\n",
    "    raise ValueError(\"No features were extracted. Check the directories and data.\")\n",
    "\n",
    "features_df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features[0].shape[0])])\n",
    "features_df['label'] = labels\n",
    "#print(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a537a-6538-4c4d-a075-e96917ba4304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_files = [os.path.join(background_noise_dir, file) for file in os.listdir(background_noise_dir) if file.endswith('.wav')]\n",
    "for i in range(len(features_df)):\n",
    "    noise = np.random.choice(noise_files)\n",
    "    y_noise, sr_noise = librosa.load(noise, duration=1.0)\n",
    "    y, sr = librosa.load(os.path.join(data_dir, features_df['label'][i], str(i) + \".wav\"), duration=1.0)\n",
    "    y += y_noise\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    features_df.iloc[i, :-1] = np.mean(mfcc.T, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7170d-2993-4f3a-838a-7d9429987ab2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05541e09-be6a-418c-a1dc-165dead24f53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Define the number of samples to select per class\n",
    "samples_per_class = 5\n",
    "\n",
    "# Loop through the speaker paths\n",
    "for i in range(len(speaker_paths)):\n",
    "    # Create a list of audio files in the current speaker folder\n",
    "    audio_files = [file for file in os.listdir(speaker_paths[i]) if file.endswith(\".wav\")]\n",
    "    \n",
    "    # Shuffle the list of audio files to ensure randomness\n",
    "    random.shuffle(audio_files)\n",
    "    \n",
    "    # Select random 5 samples from the shuffled list\n",
    "    selected_samples = audio_files[:samples_per_class]\n",
    "    \n",
    "    # Process the selected samples for this class\n",
    "    for file in selected_samples:\n",
    "        file_name = os.path.join(speaker_paths[i], file)\n",
    "        class_label = speaker_folders[i]\n",
    "        print(file_name)\n",
    "        data = extract_features(file_name)\n",
    "        features.append(data)\n",
    "        labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13874ac2-db97-4710-9a4c-6ac1323b5088",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7620c5-d206-4cfa-8f34-0d973abfb90a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to extract MFCC features from audio data\n",
    "def extract_features(audio_data, sample_rate):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "    # Display the MFCCs\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time', sr=sample_rate)\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.show()\n",
    "\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "# Define a function to sort filenames numerically\n",
    "def sort_filenames_numerically(filenames):\n",
    "    file_tuples = [(filename, int(os.path.splitext(filename)[0])) for filename in filenames if os.path.splitext(filename)[0].isdigit()]\n",
    "    sorted_tuples = sorted(file_tuples, key=lambda x: x[1])\n",
    "    sorted_filenames = [x[0] for x in sorted_tuples]\n",
    "    return sorted_filenames\n",
    "\n",
    "# Define the desired duration (in seconds) for each segment\n",
    "desired_duration = 5.0\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through the speaker paths\n",
    "for i in range(len(speaker_paths)):\n",
    "    # Create a list of audio files in the current speaker folder\n",
    "    audio_files = [file for file in os.listdir(speaker_paths[i]) if file.endswith(\".wav\")]\n",
    "    \n",
    "    # Sort the list of audio files numerically\n",
    "    audio_files = sort_filenames_numerically(audio_files)\n",
    "    \n",
    "    # Initialize variables to track segment duration and merged audio\n",
    "    current_duration = 0\n",
    "    merged_audio = np.array([])\n",
    "\n",
    "    # Process the selected samples for this class\n",
    "    merged_files = []  # Initialize a list to keep track of merged files\n",
    "    class_label = speaker_folders[i]  # Store class label\n",
    "    \n",
    "    for file in audio_files:\n",
    "        file_name = os.path.join(speaker_paths[i], file)\n",
    "        \n",
    "        # Load the audio file\n",
    "        audio, sample_rate = librosa.load(file_name, sr=None)\n",
    "        \n",
    "        # Calculate the duration of the current audio file\n",
    "        file_duration = len(audio) / sample_rate\n",
    "        \n",
    "        # Append the current filename to the merged_files list\n",
    "        merged_files.append(file)\n",
    "        \n",
    "        # Check if adding the current audio will exceed the desired duration\n",
    "        if current_duration + file_duration > desired_duration:\n",
    "            # Print the list of merged files for this segment\n",
    "            print(f\"Segment for class {class_label}: Merged files: {', '.join(merged_files)}\")\n",
    "            \n",
    "            # Extract features from the merged audio\n",
    "            features.append(extract_features(merged_audio, sample_rate))\n",
    "            labels.append(class_label)\n",
    "\n",
    "            current_duration = 0\n",
    "            merged_audio = np.array([])\n",
    "            merged_files = []  # Clear the list for the next segment\n",
    "\n",
    "        # Append the current audio to the merged segment\n",
    "        merged_audio = np.concatenate([merged_audio, audio])\n",
    "        current_duration += file_duration\n",
    "\n",
    "    # Check if there is remaining audio in the last segment\n",
    "    if len(merged_audio) > 0:\n",
    "        # Print the list of merged files for the last segment\n",
    "        print(f\"Segment for class {class_label}: Merged files: {', '.join(merged_files)}\")\n",
    "        \n",
    "        # Extract features from the merged audio\n",
    "        features.append(extract_features(merged_audio))\n",
    "        labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9471df-e198-4665-a9f8-8c6ed749a9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Function to extract MFCC features from audio data\n",
    "def extract_features(audio_data, sample_rate):\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "    # Display the MFCCs\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time', sr=sample_rate)\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.show()\n",
    "\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "# Define a function to sort filenames numerically\n",
    "def sort_filenames_numerically(filenames):\n",
    "    file_tuples = [(filename, int(os.path.splitext(filename)[0])) for filename in filenames if os.path.splitext(filename)[0].isdigit()]\n",
    "    sorted_tuples = sorted(file_tuples, key=lambda x: x[1])\n",
    "    sorted_filenames = [x[0] for x in sorted_tuples]\n",
    "    return sorted_filenames\n",
    "\n",
    "# Define the desired duration (in seconds) for each segment\n",
    "desired_duration = 5.0\n",
    "\n",
    "# Initialize lists to store features, labels, and audio paths\n",
    "features = []\n",
    "labels = []\n",
    "audio_paths = []\n",
    "\n",
    "# Loop through the speaker paths\n",
    "for i in range(len(speaker_paths)):\n",
    "    # Create a list of audio files in the current speaker folder\n",
    "    audio_files = [file for file in os.listdir(speaker_paths[i]) if file.endswith(\".wav\")]\n",
    "    \n",
    "    # Sort the list of audio files numerically\n",
    "    audio_files = sort_filenames_numerically(audio_files)\n",
    "    \n",
    "    # Initialize variables to track segment duration and merged audio\n",
    "    current_duration = 0\n",
    "    merged_audio = np.array([])\n",
    "\n",
    "    # Process the selected samples for this class\n",
    "    merged_files = []  # Initialize a list to keep track of merged files\n",
    "    class_label = speaker_folders[i]  # Store class label\n",
    "    \n",
    "    for file in audio_files:\n",
    "        file_name = os.path.join(speaker_paths[i], file)\n",
    "        \n",
    "        # Load the audio file\n",
    "        audio, sample_rate = librosa.load(file_name, sr=None)\n",
    "        audio_paths.append(file_name)  # Store the audio file path\n",
    "        \n",
    "        # Calculate the duration of the current audio file\n",
    "        file_duration = len(audio) / sample_rate\n",
    "        \n",
    "        # Append the current filename to the merged_files list\n",
    "        merged_files.append(file)\n",
    "        \n",
    "        # Check if adding the current audio will exceed the desired duration\n",
    "        if current_duration + file_duration > desired_duration:\n",
    "            # Print the list of merged files for this segment\n",
    "            print(f\"Segment for class {class_label}: Merged files: {', '.join(merged_files)}\")\n",
    "            \n",
    "            # Play the merged audio\n",
    "            display(Audio(data=merged_audio, rate=sample_rate))\n",
    "            \n",
    "            # Extract features from the merged audio\n",
    "            features.append(extract_features(merged_audio, sample_rate))\n",
    "            labels.append(class_label)\n",
    "            \n",
    "            current_duration = 0\n",
    "            merged_audio = np.array([])\n",
    "            merged_files = []  # Clear the list for the next segment\n",
    "\n",
    "        # Append the current audio to the merged segment\n",
    "        merged_audio = np.concatenate([merged_audio, audio])\n",
    "        current_duration += file_duration\n",
    "\n",
    "    # Check if there is remaining audio in the last segment\n",
    "    if len(merged_audio) > 0:\n",
    "        # Print the list of merged files for the last segment\n",
    "        print(f\"Segment for class {class_label}: Merged files: {', '.join(merged_files)}\")\n",
    "        \n",
    "        # Play the merged audio\n",
    "        display(Audio(data=merged_audio, rate=sample_rate))\n",
    "        \n",
    "        # Extract features from the merged audio\n",
    "        features.append(extract_features(merged_audio, sample_rate))\n",
    "        labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4fa07-701a-49c7-ab7b-8f9e286ed50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c1243-81e9-440e-9002-29f25dd70228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151f8a5-1c1c-49c4-921d-acf23c835fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bc208-c8ce-4ffd-8ba6-c1369d22a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_df)):\n",
    "    noise = np.random.choice(noise_files)\n",
    "    y_noise, sr_noise = librosa.load(noise, duration=1.0)\n",
    "    try:\n",
    "        audio_file_path = os.path.join(data_dir, features_df['label'][i], str(i) + \".wav\")\n",
    "        y, sr = librosa.load(audio_file_path, duration=1.0)\n",
    "        y += y_noise\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        features_df.iloc[i, :-1] = np.mean(mfcc.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacaafab-8749-4413-9f52-43e5e5dfd38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883f71-a6ae-43a6-84f6-c75c8216a158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
